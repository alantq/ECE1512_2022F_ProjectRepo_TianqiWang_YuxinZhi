{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8477d-5b65-4966-846d-ae846bb50a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from\n",
    "# https://github.com/VICO-UoE/DatasetCondensation\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import kornia as K\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.ndimage.interpolation import rotate as scipyrotate\n",
    "from ipynb.fs.full.networks import MLP, ConvNet, LeNet, AlexNet, VGG11BN, VGG11, ResNet18, ResNet18BN_AP, ResNet18_AP\n",
    "\n",
    "class Config:\n",
    "    imagenette = [0, 217, 482, 491, 497, 566, 569, 571, 574, 701]\n",
    "\n",
    "    # [\"australian_terrier\", \"border_terrier\", \"samoyed\", \"beagle\", \"shih-tzu\", \"english_foxhound\", \"rhodesian_ridgeback\", \"dingo\", \"golden_retriever\", \"english_sheepdog\"]\n",
    "    imagewoof = [193, 182, 258, 162, 155, 167, 159, 273, 207, 229]\n",
    "\n",
    "    # [\"tabby_cat\", \"bengal_cat\", \"persian_cat\", \"siamese_cat\", \"egyptian_cat\", \"lion\", \"tiger\", \"jaguar\", \"snow_leopard\", \"lynx\"]\n",
    "    imagemeow = [281, 282, 283, 284, 285, 291, 292, 290, 289, 287]\n",
    "\n",
    "    # [\"peacock\", \"flamingo\", \"macaw\", \"pelican\", \"king_penguin\", \"bald_eagle\", \"toucan\", \"ostrich\", \"black_swan\", \"cockatoo\"]\n",
    "    imagesquawk = [84, 130, 88, 144, 145, 22, 96, 9, 100, 89]\n",
    "\n",
    "    # [\"pineapple\", \"banana\", \"strawberry\", \"orange\", \"lemon\", \"pomegranate\", \"fig\", \"bell_pepper\", \"cucumber\", \"green_apple\"]\n",
    "    imagefruit = [953, 954, 949, 950, 951, 957, 952, 945, 943, 948]\n",
    "\n",
    "    # [\"bee\", \"ladys slipper\", \"banana\", \"lemon\", \"corn\", \"school_bus\", \"honeycomb\", \"lion\", \"garden_spider\", \"goldfinch\"]\n",
    "    imageyellow = [309, 986, 954, 951, 987, 779, 599, 291, 72, 11]\n",
    "\n",
    "    dict = {\n",
    "        \"imagenette\" : imagenette,\n",
    "        \"imagewoof\" : imagewoof,\n",
    "        \"imagefruit\": imagefruit,\n",
    "        \"imageyellow\": imageyellow,\n",
    "        \"imagemeow\": imagemeow,\n",
    "        \"imagesquawk\": imagesquawk,\n",
    "    }\n",
    "\n",
    "config = Config()\n",
    "\n",
    "def get_dataset(dataset, data_path, batch_size=1, subset=\"imagenette\", args=None):\n",
    "\n",
    "    class_map = None\n",
    "    loader_train_dict = None\n",
    "    class_map_inv = None\n",
    "\n",
    "    if dataset == 'CIFAR10':\n",
    "        channel = 3\n",
    "        im_size = (32, 32)\n",
    "        num_classes = 10\n",
    "        mean = [0.4914, 0.4822, 0.4465]\n",
    "        std = [0.2023, 0.1994, 0.2010]\n",
    "        if args.zca:\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "        dst_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform) # no augmentation\n",
    "        dst_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
    "        class_names = dst_train.classes\n",
    "        class_map = {x:x for x in range(num_classes)}\n",
    "\n",
    "\n",
    "    elif dataset == 'Tiny':\n",
    "        channel = 3\n",
    "        im_size = (64, 64)\n",
    "        num_classes = 200\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        if args.zca:\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "        dst_train = datasets.ImageFolder(os.path.join(data_path, \"train\"), transform=transform) # no augmentation\n",
    "        dst_test = datasets.ImageFolder(os.path.join(data_path, \"val\", \"images\"), transform=transform)\n",
    "        class_names = dst_train.classes\n",
    "        class_map = {x:x for x in range(num_classes)}\n",
    "\n",
    "\n",
    "    elif dataset == 'ImageNet':\n",
    "        channel = 3\n",
    "        im_size = (128, 128)\n",
    "        num_classes = 10\n",
    "\n",
    "        config.img_net_classes = config.dict[subset]\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        if args.zca:\n",
    "            transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize(im_size),\n",
    "                                        transforms.CenterCrop(im_size)])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=mean, std=std),\n",
    "                                            transforms.Resize(im_size),\n",
    "                                            transforms.CenterCrop(im_size)])\n",
    "\n",
    "        dst_train = datasets.ImageNet(data_path, split=\"train\", transform=transform) # no augmentation\n",
    "        dst_train_dict = {c : torch.utils.data.Subset(dst_train, np.squeeze(np.argwhere(np.equal(dst_train.targets, config.img_net_classes[c])))) for c in range(len(config.img_net_classes))}\n",
    "        dst_train = torch.utils.data.Subset(dst_train, np.squeeze(np.argwhere(np.isin(dst_train.targets, config.img_net_classes))))\n",
    "        loader_train_dict = {c : torch.utils.data.DataLoader(dst_train_dict[c], batch_size=batch_size, shuffle=True, num_workers=16) for c in range(len(config.img_net_classes))}\n",
    "        dst_test = datasets.ImageNet(data_path, split=\"val\", transform=transform)\n",
    "        dst_test = torch.utils.data.Subset(dst_test, np.squeeze(np.argwhere(np.isin(dst_test.targets, config.img_net_classes))))\n",
    "        for c in range(len(config.img_net_classes)):\n",
    "            dst_test.dataset.targets[dst_test.dataset.targets == config.img_net_classes[c]] = c\n",
    "            dst_train.dataset.targets[dst_train.dataset.targets == config.img_net_classes[c]] = c\n",
    "        print(dst_test.dataset)\n",
    "        class_map = {x: i for i, x in enumerate(config.img_net_classes)}\n",
    "        class_map_inv = {i: x for i, x in enumerate(config.img_net_classes)}\n",
    "        class_names = None\n",
    "\n",
    "\n",
    "    elif dataset.startswith('CIFAR100'):\n",
    "        channel = 3\n",
    "        im_size = (32, 32)\n",
    "        num_classes = 100\n",
    "        mean = [0.4914, 0.4822, 0.4465]\n",
    "        std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "        if args.zca:\n",
    "            transform = transforms.Compose([transforms.ToTensor()])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "        dst_train = datasets.CIFAR100(data_path, train=True, download=True, transform=transform)  # no augmentation\n",
    "        dst_test = datasets.CIFAR100(data_path, train=False, download=True, transform=transform)\n",
    "        class_names = dst_train.classes\n",
    "        class_map = {x: x for x in range(num_classes)}\n",
    "\n",
    "    else:\n",
    "        exit('unknown dataset: %s'%dataset)\n",
    "\n",
    "    if args.zca:\n",
    "        images = []\n",
    "        labels = []\n",
    "        print(\"Train ZCA\")\n",
    "        for i in tqdm.tqdm(range(len(dst_train))):\n",
    "            im, lab = dst_train[i]\n",
    "            images.append(im)\n",
    "            labels.append(lab)\n",
    "        images = torch.stack(images, dim=0).to(args.device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long, device=\"cpu\")\n",
    "        zca = K.enhance.ZCAWhitening(eps=0.1, compute_inv=True)\n",
    "        zca.fit(images)\n",
    "        zca_images = zca(images).to(\"cpu\")\n",
    "        dst_train = TensorDataset(zca_images, labels)\n",
    "\n",
    "        images = []\n",
    "        labels = []\n",
    "        print(\"Test ZCA\")\n",
    "        for i in tqdm.tqdm(range(len(dst_test))):\n",
    "            im, lab = dst_test[i]\n",
    "            images.append(im)\n",
    "            labels.append(lab)\n",
    "        images = torch.stack(images, dim=0).to(args.device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long, device=\"cpu\")\n",
    "\n",
    "        zca_images = zca(images).to(\"cpu\")\n",
    "        dst_test = TensorDataset(zca_images, labels)\n",
    "\n",
    "        args.zca_trans = zca\n",
    "\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(dst_test, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "    return channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader, loader_train_dict, class_map, class_map_inv\n",
    "\n",
    "\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, images, labels): # images: n x c x h x w tensor\n",
    "        self.images = images.detach().float()\n",
    "        self.labels = labels.detach()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "def get_default_convnet_setting():\n",
    "    net_width, net_depth, net_act, net_norm, net_pooling = 128, 3, 'relu', 'instancenorm', 'avgpooling'\n",
    "    return net_width, net_depth, net_act, net_norm, net_pooling\n",
    "\n",
    "\n",
    "\n",
    "def get_network(model, channel, num_classes, im_size=(32, 32), dist=True):\n",
    "    torch.random.manual_seed(int(time.time() * 1000) % 100000)\n",
    "    net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
    "\n",
    "    if model == 'MLP':\n",
    "        net = MLP(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'ConvNet':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'LeNet':\n",
    "        net = LeNet(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'AlexNet':\n",
    "        net = AlexNet(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'VGG11':\n",
    "        net = VGG11( channel=channel, num_classes=num_classes)\n",
    "    elif model == 'VGG11BN':\n",
    "        net = VGG11BN(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'ResNet18':\n",
    "        net = ResNet18(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'ResNet18BN_AP':\n",
    "        net = ResNet18BN_AP(channel=channel, num_classes=num_classes)\n",
    "    elif model == 'ResNet18_AP':\n",
    "        net = ResNet18_AP(channel=channel, num_classes=num_classes)\n",
    "\n",
    "    elif model == 'ConvNetD1':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=1, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD2':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=2, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD3':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=3, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD4':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=4, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD5':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=5, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD6':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=6, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD7':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=7, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "    elif model == 'ConvNetD8':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=8, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
    "\n",
    "\n",
    "    elif model == 'ConvNetW32':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=32, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetW64':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=64, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetW128':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=128, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetW256':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=256, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetW512':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=512, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetW1024':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=1024, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling)\n",
    "\n",
    "    elif model == \"ConvNetKIP\":\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=1024, net_depth=net_depth, net_act=net_act,\n",
    "                      net_norm=\"none\", net_pooling=net_pooling)\n",
    "\n",
    "    elif model == 'ConvNetAS':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='sigmoid', net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetAR':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='relu', net_norm=net_norm, net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetAL':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='leakyrelu', net_norm=net_norm, net_pooling=net_pooling)\n",
    "\n",
    "    elif model == 'ConvNetNN':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='none', net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetBN':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='batchnorm', net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetLN':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='layernorm', net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetIN':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='instancenorm', net_pooling=net_pooling)\n",
    "    elif model == 'ConvNetGN':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='groupnorm', net_pooling=net_pooling)\n",
    "\n",
    "    elif model == 'ConvNetNP':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='none')\n",
    "    elif model == 'ConvNetMP':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='maxpooling')\n",
    "    elif model == 'ConvNetAP':\n",
    "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='avgpooling')\n",
    "\n",
    "\n",
    "    else:\n",
    "        net = None\n",
    "        exit('DC error: unknown model')\n",
    "\n",
    "    if dist:\n",
    "        gpu_num = torch.cuda.device_count()\n",
    "        if gpu_num>0:\n",
    "            device = 'cuda'\n",
    "            if gpu_num>1:\n",
    "                net = nn.DataParallel(net)\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "        net = net.to(device)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "def get_time():\n",
    "    return str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
    "\n",
    "\n",
    "def epoch(mode, dataloader, net, optimizer, criterion, args, aug, texture=False):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "    net = net.to(args.device)\n",
    "\n",
    "    if args.dataset == \"ImageNet\":\n",
    "        class_map = {x: i for i, x in enumerate(config.img_net_classes)}\n",
    "\n",
    "    if mode == 'train':\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0].float().to(args.device)\n",
    "        lab = datum[1].long().to(args.device)\n",
    "\n",
    "        if mode == \"train\" and texture:\n",
    "            img = torch.cat([torch.stack([torch.roll(im, (torch.randint(args.im_size[0]*args.canvas_size, (1,)), torch.randint(args.im_size[0]*args.canvas_size, (1,))), (1,2))[:,:args.im_size[0],:args.im_size[1]] for im in img]) for _ in range(args.canvas_samples)])\n",
    "            lab = torch.cat([lab for _ in range(args.canvas_samples)])\n",
    "\n",
    "        if aug:\n",
    "            if args.dsa:\n",
    "                img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n",
    "            else:\n",
    "                img = augment(img, args.dc_aug_param, device=args.device)\n",
    "\n",
    "        if args.dataset == \"ImageNet\" and mode != \"train\":\n",
    "            lab = torch.tensor([class_map[x.item()] for x in lab]).to(args.device)\n",
    "\n",
    "        n_b = lab.shape[0]\n",
    "\n",
    "        output = net(img)\n",
    "        loss = criterion(output, lab)\n",
    "\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_synset(it_eval, net, images_train, labels_train, testloader, args, return_loss=False, texture=False):\n",
    "    net = net.to(args.device)\n",
    "    images_train = images_train.to(args.device)\n",
    "    labels_train = labels_train.to(args.device)\n",
    "    lr = float(args.lr_net)\n",
    "    Epoch = int(args.epoch_eval_train)\n",
    "    lr_schedule = [Epoch//2+1]\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "    dst_train = TensorDataset(images_train, labels_train)\n",
    "    trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
    "\n",
    "    start = time.time()\n",
    "    acc_train_list = []\n",
    "    loss_train_list = []\n",
    "\n",
    "    for ep in tqdm.tqdm(range(Epoch+1)):\n",
    "        loss_train, acc_train = epoch('train', trainloader, net, optimizer, criterion, args, aug=True, texture=texture)\n",
    "        acc_train_list.append(acc_train)\n",
    "        loss_train_list.append(loss_train)\n",
    "        if ep == Epoch:\n",
    "            with torch.no_grad():\n",
    "                loss_test, acc_test = epoch('test', testloader, net, optimizer, criterion, args, aug=False)\n",
    "        if ep in lr_schedule:\n",
    "            lr *= 0.1\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "    time_train = time.time() - start\n",
    "\n",
    "    print('%s Evaluate_%02d: epoch = %04d train time = %d s train loss = %.6f train acc = %.4f, test acc = %.4f' % (get_time(), it_eval, Epoch, int(time_train), loss_train, acc_train, acc_test))\n",
    "\n",
    "    if return_loss:\n",
    "        return net, acc_train_list, acc_test, loss_train_list, loss_test\n",
    "    else:\n",
    "        return net, acc_train_list, acc_test\n",
    "\n",
    "\n",
    "def augment(images, dc_aug_param, device):\n",
    "    # This can be sped up in the future.\n",
    "\n",
    "    if dc_aug_param != None and dc_aug_param['strategy'] != 'none':\n",
    "        scale = dc_aug_param['scale']\n",
    "        crop = dc_aug_param['crop']\n",
    "        rotate = dc_aug_param['rotate']\n",
    "        noise = dc_aug_param['noise']\n",
    "        strategy = dc_aug_param['strategy']\n",
    "\n",
    "        shape = images.shape\n",
    "        mean = []\n",
    "        for c in range(shape[1]):\n",
    "            mean.append(float(torch.mean(images[:,c])))\n",
    "\n",
    "        def cropfun(i):\n",
    "            im_ = torch.zeros(shape[1],shape[2]+crop*2,shape[3]+crop*2, dtype=torch.float, device=device)\n",
    "            for c in range(shape[1]):\n",
    "                im_[c] = mean[c]\n",
    "            im_[:, crop:crop+shape[2], crop:crop+shape[3]] = images[i]\n",
    "            r, c = np.random.permutation(crop*2)[0], np.random.permutation(crop*2)[0]\n",
    "            images[i] = im_[:, r:r+shape[2], c:c+shape[3]]\n",
    "\n",
    "        def scalefun(i):\n",
    "            h = int((np.random.uniform(1 - scale, 1 + scale)) * shape[2])\n",
    "            w = int((np.random.uniform(1 - scale, 1 + scale)) * shape[2])\n",
    "            tmp = F.interpolate(images[i:i + 1], [h, w], )[0]\n",
    "            mhw = max(h, w, shape[2], shape[3])\n",
    "            im_ = torch.zeros(shape[1], mhw, mhw, dtype=torch.float, device=device)\n",
    "            r = int((mhw - h) / 2)\n",
    "            c = int((mhw - w) / 2)\n",
    "            im_[:, r:r + h, c:c + w] = tmp\n",
    "            r = int((mhw - shape[2]) / 2)\n",
    "            c = int((mhw - shape[3]) / 2)\n",
    "            images[i] = im_[:, r:r + shape[2], c:c + shape[3]]\n",
    "\n",
    "        def rotatefun(i):\n",
    "            im_ = scipyrotate(images[i].cpu().data.numpy(), angle=np.random.randint(-rotate, rotate), axes=(-2, -1), cval=np.mean(mean))\n",
    "            r = int((im_.shape[-2] - shape[-2]) / 2)\n",
    "            c = int((im_.shape[-1] - shape[-1]) / 2)\n",
    "            images[i] = torch.tensor(im_[:, r:r + shape[-2], c:c + shape[-1]], dtype=torch.float, device=device)\n",
    "\n",
    "        def noisefun(i):\n",
    "            images[i] = images[i] + noise * torch.randn(shape[1:], dtype=torch.float, device=device)\n",
    "\n",
    "\n",
    "        augs = strategy.split('_')\n",
    "\n",
    "        for i in range(shape[0]):\n",
    "            choice = np.random.permutation(augs)[0] # randomly implement one augmentation\n",
    "            if choice == 'crop':\n",
    "                cropfun(i)\n",
    "            elif choice == 'scale':\n",
    "                scalefun(i)\n",
    "            elif choice == 'rotate':\n",
    "                rotatefun(i)\n",
    "            elif choice == 'noise':\n",
    "                noisefun(i)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "def get_daparam(dataset, model, model_eval, ipc):\n",
    "    # We find that augmentation doesn't always benefit the performance.\n",
    "    # So we do augmentation for some of the settings.\n",
    "\n",
    "    dc_aug_param = dict()\n",
    "    dc_aug_param['crop'] = 4\n",
    "    dc_aug_param['scale'] = 0.2\n",
    "    dc_aug_param['rotate'] = 45\n",
    "    dc_aug_param['noise'] = 0.001\n",
    "    dc_aug_param['strategy'] = 'none'\n",
    "\n",
    "    if dataset == 'MNIST':\n",
    "        dc_aug_param['strategy'] = 'crop_scale_rotate'\n",
    "\n",
    "    if model_eval in ['ConvNetBN']:  # Data augmentation makes model training with Batch Norm layer easier.\n",
    "        dc_aug_param['strategy'] = 'crop_noise'\n",
    "\n",
    "    return dc_aug_param\n",
    "\n",
    "\n",
    "def get_eval_pool(eval_mode, model, model_eval):\n",
    "    if eval_mode == 'M': # multiple architectures\n",
    "        # model_eval_pool = ['MLP', 'ConvNet', 'AlexNet', 'VGG11', 'ResNet18', 'LeNet']\n",
    "        model_eval_pool = ['ConvNet', 'AlexNet', 'VGG11', 'ResNet18_AP', 'ResNet18']\n",
    "        # model_eval_pool = ['MLP', 'ConvNet', 'AlexNet', 'VGG11', 'ResNet18']\n",
    "    elif eval_mode == 'W': # ablation study on network width\n",
    "        model_eval_pool = ['ConvNetW32', 'ConvNetW64', 'ConvNetW128', 'ConvNetW256']\n",
    "    elif eval_mode == 'D': # ablation study on network depth\n",
    "        model_eval_pool = ['ConvNetD1', 'ConvNetD2', 'ConvNetD3', 'ConvNetD4']\n",
    "    elif eval_mode == 'A': # ablation study on network activation function\n",
    "        model_eval_pool = ['ConvNetAS', 'ConvNetAR', 'ConvNetAL']\n",
    "    elif eval_mode == 'P': # ablation study on network pooling layer\n",
    "        model_eval_pool = ['ConvNetNP', 'ConvNetMP', 'ConvNetAP']\n",
    "    elif eval_mode == 'N': # ablation study on network normalization layer\n",
    "        model_eval_pool = ['ConvNetNN', 'ConvNetBN', 'ConvNetLN', 'ConvNetIN', 'ConvNetGN']\n",
    "    elif eval_mode == 'S': # itself\n",
    "        model_eval_pool = [model[:model.index('BN')]] if 'BN' in model else [model]\n",
    "    elif eval_mode == 'C':\n",
    "        model_eval_pool = [model, 'ConvNet']\n",
    "    else:\n",
    "        model_eval_pool = [model_eval]\n",
    "    return model_eval_pool\n",
    "\n",
    "\n",
    "class ParamDiffAug():\n",
    "    def __init__(self):\n",
    "        self.aug_mode = 'S' #'multiple or single'\n",
    "        self.prob_flip = 0.5\n",
    "        self.ratio_scale = 1.2\n",
    "        self.ratio_rotate = 15.0\n",
    "        self.ratio_crop_pad = 0.125\n",
    "        self.ratio_cutout = 0.5 # the size would be 0.5x0.5\n",
    "        self.ratio_noise = 0.05\n",
    "        self.brightness = 1.0\n",
    "        self.saturation = 2.0\n",
    "        self.contrast = 0.5\n",
    "\n",
    "\n",
    "def set_seed_DiffAug(param):\n",
    "    if param.latestseed == -1:\n",
    "        return\n",
    "    else:\n",
    "        torch.random.manual_seed(param.latestseed)\n",
    "        param.latestseed += 1\n",
    "\n",
    "\n",
    "def DiffAugment(x, strategy='', seed = -1, param = None):\n",
    "    if seed == -1:\n",
    "        param.batchmode = False\n",
    "    else:\n",
    "        param.batchmode = True\n",
    "\n",
    "    param.latestseed = seed\n",
    "\n",
    "    if strategy == 'None' or strategy == 'none':\n",
    "        return x\n",
    "\n",
    "    if strategy:\n",
    "        if param.aug_mode == 'M': # original\n",
    "            for p in strategy.split('_'):\n",
    "                for f in AUGMENT_FNS[p]:\n",
    "                    x = f(x, param)\n",
    "        elif param.aug_mode == 'S':\n",
    "            pbties = strategy.split('_')\n",
    "            set_seed_DiffAug(param)\n",
    "            p = pbties[torch.randint(0, len(pbties), size=(1,)).item()]\n",
    "            for f in AUGMENT_FNS[p]:\n",
    "                x = f(x, param)\n",
    "        else:\n",
    "            exit('Error ZH: unknown augmentation mode.')\n",
    "        x = x.contiguous()\n",
    "    return x\n",
    "\n",
    "\n",
    "# We implement the following differentiable augmentation strategies based on the code provided in https://github.com/mit-han-lab/data-efficient-gans.\n",
    "def rand_scale(x, param):\n",
    "    # x>1, max scale\n",
    "    # sx, sy: (0, +oo), 1: orignial size, 0.5: enlarge 2 times\n",
    "    ratio = param.ratio_scale\n",
    "    set_seed_DiffAug(param)\n",
    "    sx = torch.rand(x.shape[0]) * (ratio - 1.0/ratio) + 1.0/ratio\n",
    "    set_seed_DiffAug(param)\n",
    "    sy = torch.rand(x.shape[0]) * (ratio - 1.0/ratio) + 1.0/ratio\n",
    "    theta = [[[sx[i], 0,  0],\n",
    "            [0,  sy[i], 0],] for i in range(x.shape[0])]\n",
    "    theta = torch.tensor(theta, dtype=torch.float)\n",
    "    if param.batchmode: # batch-wise:\n",
    "        theta[:] = theta[0]\n",
    "    grid = F.affine_grid(theta, x.shape, align_corners=True).to(x.device)\n",
    "    x = F.grid_sample(x, grid, align_corners=True)\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_rotate(x, param): # [-180, 180], 90: anticlockwise 90 degree\n",
    "    ratio = param.ratio_rotate\n",
    "    set_seed_DiffAug(param)\n",
    "    theta = (torch.rand(x.shape[0]) - 0.5) * 2 * ratio / 180 * float(np.pi)\n",
    "    theta = [[[torch.cos(theta[i]), torch.sin(-theta[i]), 0],\n",
    "        [torch.sin(theta[i]), torch.cos(theta[i]),  0],]  for i in range(x.shape[0])]\n",
    "    theta = torch.tensor(theta, dtype=torch.float)\n",
    "    if param.batchmode: # batch-wise:\n",
    "        theta[:] = theta[0]\n",
    "    grid = F.affine_grid(theta, x.shape, align_corners=True).to(x.device)\n",
    "    x = F.grid_sample(x, grid, align_corners=True)\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_flip(x, param):\n",
    "    prob = param.prob_flip\n",
    "    set_seed_DiffAug(param)\n",
    "    randf = torch.rand(x.size(0), 1, 1, 1, device=x.device)\n",
    "    if param.batchmode: # batch-wise:\n",
    "        randf[:] = randf[0]\n",
    "    return torch.where(randf < prob, x.flip(3), x)\n",
    "\n",
    "\n",
    "def rand_brightness(x, param):\n",
    "    ratio = param.brightness\n",
    "    set_seed_DiffAug(param)\n",
    "    randb = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
    "    if param.batchmode:  # batch-wise:\n",
    "        randb[:] = randb[0]\n",
    "    x = x + (randb - 0.5)*ratio\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_saturation(x, param):\n",
    "    ratio = param.saturation\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    set_seed_DiffAug(param)\n",
    "    rands = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
    "    if param.batchmode:  # batch-wise:\n",
    "        rands[:] = rands[0]\n",
    "    x = (x - x_mean) * (rands * ratio) + x_mean\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_contrast(x, param):\n",
    "    ratio = param.contrast\n",
    "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
    "    set_seed_DiffAug(param)\n",
    "    randc = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
    "    if param.batchmode:  # batch-wise:\n",
    "        randc[:] = randc[0]\n",
    "    x = (x - x_mean) * (randc + ratio) + x_mean\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_crop(x, param):\n",
    "    # The image is padded on its surrounding and then cropped.\n",
    "    ratio = param.ratio_crop_pad\n",
    "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    set_seed_DiffAug(param)\n",
    "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    set_seed_DiffAug(param)\n",
    "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    if param.batchmode:  # batch-wise:\n",
    "        translation_x[:] = translation_x[0]\n",
    "        translation_y[:] = translation_y[0]\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
    "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
    "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
    "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
    "    return x\n",
    "\n",
    "\n",
    "def rand_cutout(x, param):\n",
    "    ratio = param.ratio_cutout\n",
    "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    set_seed_DiffAug(param)\n",
    "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    set_seed_DiffAug(param)\n",
    "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    if param.batchmode:  # batch-wise:\n",
    "        offset_x[:] = offset_x[0]\n",
    "        offset_y[:] = offset_y[0]\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
    "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
    "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
    "    mask[grid_batch, grid_x, grid_y] = 0\n",
    "    x = x * mask.unsqueeze(1)\n",
    "    return x\n",
    "\n",
    "\n",
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
    "    'crop': [rand_crop],\n",
    "    'cutout': [rand_cutout],\n",
    "    'flip': [rand_flip],\n",
    "    'scale': [rand_scale],\n",
    "    'rotate': [rand_rotate],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
